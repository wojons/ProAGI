## Goal: Implement the `OptimizationOracle` Service

Implement the `OptimizationOracle` responsible for analyzing metrics, applying rules, and initiating the JIT code generation process. Based on Section 3.6 [16] and Section 7 [10, 22].

**Context:**
*   Dependencies: `MetricCollectorInterface` (or direct client if standalone), `StateManagerInterface`, `ApplicationRegistryInterface`, `CoreMCPServer` (for Coder LLM via MCP).
*   Data Models: `@core/shared/data_models.py` (`AppDefinition`, `ComponentDefinition`, `OptimizationConfig`)
*   Design Docs: Section 3.6 [16], Section 7 [10, 22], `07-jit-optimization.md` [10]
*   Project Standards: `@.clinerules`

**Plan:**

1.  **Define Interface (Optional):** Use `write_to_file` to create `core/interfaces/optimization_oracle_interface.py`. Define an ABC, maybe with an `async def run_optimization_cycle(self)` method.
2.  **Create Implementation File:** Use `write_to_file` to create `core/optimization/optimization_oracle.py`.
3.  **Import Dependencies:** Import interfaces (`MetricCollectorInterface`, `StateManagerInterface`, `ApplicationRegistryInterface`), MCP client logic (needs a way to call `core.llm.generate`), data models, `asyncio`, `logging`, `json`.
4.  **Implement `OptimizationOracle` Class:**
    *   **Initialization (`__init__`)**:
        *   Accept dependencies: `app_registry`, `state_manager`, `metric_collector`, `mcp_client` (or similar mechanism to call MCP).
        *   Initialize a logger.
        *   Store configuration (e.g., Coder LLM model ID, default optimization rules).
    *   **Main Logic (`run_optimization_cycle` or similar periodic task):**
        *   Get list of active applications from `app_registry`.
        *   For each application:
            *   Get `AppDefinition` and its `OptimizationConfig` from `app_registry`.
            *   Get relevant metrics for this app from `metric_collector` (API TBD - needs query capability or relies on structured metric labels). Query metrics like P95 latency, call count, cost estimate (if available) for LLM components.
            *   Iterate through components in the app's `ComponentRegistry` (part of `AppDefinition`).
            *   For each component currently using `handlerType: LLM`:
                *   Apply rules defined in `OptimizationConfig` (e.g., "if calls > 100/min AND p95_latency > 500ms then optimize").
                *   If rules trigger optimization:
                    *   Log decision to optimize `app_id`/`component_id`.
                    *   Call `_trigger_jit_generation(app_id, component_id, component_def)`.
    *   **JIT Generation Trigger (`_trigger_jit_generation` internal async method):**
        *   **Formulate Spec (Section 7.3.1 [10]):**
            *   Retrieve current LLM prompt template path from `component_def`.
            *   Fetch prompt template content using `state_manager.get_definition_file_content`.
            *   Fetch example observed inputs/outputs if available (needs metric/logging source - V1 might skip this).
            *   Parse prompt template metadata (`outputSchema`, `description`).
            *   Construct a detailed text specification for the Coder LLM: function signature (derive from inputs/`outputSchema`), purpose (from description), core logic (from prompt), input data examples (if available), output format requirements (`outputSchema`), target language (from `AppDefinition` or global config), request for unit tests.
        *   **Invoke Coder LLM (Section 7.3.2 [10]):**
            *   Prepare params for `core.llm.generate`, including the detailed specification as the prompt, Coder LLM model ID, desired output format (e.g., JSON block containing `code` and `tests`).
            *   Use `mcp_client.call_tool("core.llm.generate", params, context={...})`. Handle MCP errors.
        *   **Process Coder Response:**
            *   Parse the LLM response (extract code string, test string). Handle parsing failures.
        *   **Store Artifacts (Section 7.3.3):**
            *   Determine new version/path for JIT code (e.g., `_jit_code/{component_id}/v{N}/handler.py`).
            *   Use `state_manager.set_definition_file_content` to save the generated `code` to the handler path with a commit message.
            *   Use `state_manager.set_definition_file_content` to save the generated `tests` to `_jit_code/{component_id}/v{N}/test_handler.py` with a commit message.
        *   **Execute Tests (CRITICAL - requires coordination/MCP Tool - Placeholder for 5.6):**
            *   *Placeholder:* Add a log statement indicating where tests should be executed. The actual execution involves calling another MCP tool or process. Assume tests pass for V0.1 implementation.
        *   **Update Component Registry (Section 7.3.3):**
            *   Fetch the current `component_registry.yaml` (or equivalent state file) using `state_manager`.
            *   Modify the entry for the `component_id`: change `handlerType` to `JIT`, update `taskDetails` to point to the new script path and function name.
            *   Use `state_manager.apply_definition_diff` or `set_definition_file_content` to commit the updated registry file. Handle commit failures (rollback artifact save?).
            *   Log successful JIT deployment.
5.  **Scheduling:** Determine how `run_optimization_cycle` is triggered (e.g., `asyncio.create_task` with `asyncio.sleep` in the main framework server, or external cron/scheduler).
6.  **Add Basic Unit Tests:** Use `write_to_file` to create `tests/core/optimization/test_optimization_oracle.py`.
    *   Use `pytest` and mock all dependencies (`ApplicationRegistry`, `StateManager`, `MetricCollector`, `mcp_client`).
    *   Test the main loop logic: fetching apps, applying rules (mock metrics), triggering generation.
    *   Test `_trigger_jit_generation`: mock spec formulation inputs, mock Coder LLM response, verify calls to `StateManager` to save artifacts and update registry.

**Expected Outcome:**
*   `core/optimization/optimization_oracle.py` containing the `OptimizationOracle` implementation.
*   Logic for periodic execution integrated somewhere.
*   Basic unit tests in `tests/core/optimization/test_optimization_oracle.py`.