## Goal: Implement Basic Metric Querying for OptimizationOracle

Implement a basic mechanism for the `OptimizationOracle` to query relevant metrics (e.g., latency, count) from the `MetricCollector` to make optimization decisions.

**Context:**
*   Oracle Code: `@core/optimization/optimization_oracle.py`
*   Metric Collector Code: `@core/metrics/metric_collector.py`
*   Metric Collector Interface: `@core/interfaces/metric_collector_interface.py`
*   Dependencies: `prometheus-client` (within Collector).

**Plan:**

1.  **Define Query Interface Method:**
    *   Use `read_file` to load `@core/interfaces/metric_collector_interface.py`.
    *   Add a new abstract method: `async def query_metric(self, metric_name: str, labels: Dict[str, str], window: str = "5m") -> Optional[float]:` (or return a more complex structure). The `window` is conceptual for now.
    *   Use `write_to_file` to save changes.
2.  **Implement Basic Query Method in `MetricCollector`:**
    *   Use `read_file` to load `@core/metrics/metric_collector.py`.
    *   Implement the `query_metric` method in the `MetricCollector` class.
    *   **Challenge:** Directly querying aggregated values (like P95 over time) from the in-memory `prometheus-client` objects is non-trivial.
    *   **V1 Approach (Simple Gauge/Counter Lookup):**
        *   Find the metric object in `self._metrics` using `metric_name`. Handle not found.
        *   If it's a `Gauge` or `Counter`, try to get the current value specific to the *exact* `labels` provided using `.labels(**labels).collect()[0].samples[0].value`. This only gives the *current* value, not aggregates over time. Handle label mismatch errors.
        *   If it's a `Histogram`/`Summary`, accessing aggregated quantiles directly is hard. Return `None` or log a "Not Implemented" message for these types in V1.
    *   **Add TODO for PromQL:** Add a comment: `# TODO: Implement proper metric querying using Prometheus/PromQL endpoint instead of direct object access for time-windowed aggregates (e.g., P95 latency, avg count).`
    *   Return the found value or `None`.
    *   Use `write_to_file` to save changes.
3.  **Update `OptimizationOracle` to Use Query:**
    *   Use `read_file` to load `@core/optimization/optimization_oracle.py`.
    *   In the main optimization loop (`run_optimization_cycle` or similar):
        *   Replace the placeholder metric fetching logic.
        *   For each LLM component, construct the required `labels` (e.g., `appId`, `componentId`).
        *   Call `await self.metric_collector.query_metric("uhlp_framework_request_duration_ms", labels=component_labels)` (or relevant latency metric).
        *   Call `await self.metric_collector.query_metric("uhlp_framework_request_total", labels=component_labels)` (or relevant count metric).
        *   Use the returned values (handling `None`) in the optimization rule evaluation (`if latency is not None and latency > threshold...`).
    *   Use `write_to_file` to save changes.
4.  **Update Tests:**
    *   Update tests for `MetricCollector` to cover the basic `query_metric` implementation.
    *   Update tests for `OptimizationOracle` to mock `metric_collector.query_metric` returning different values to test the rule logic.

**Expected Outcome:**
*   `MetricCollectorInterface` and `MetricCollector` have a basic `query_metric` method (limited to current gauge/counter values by exact labels).
*   `OptimizationOracle` calls `query_metric` to retrieve *current* metric values for rule evaluation.
*   Comments indicate the need for a proper PromQL-based solution for real time-windowed aggregates.