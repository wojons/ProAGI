## Goal: Implement the Workflow Execution Engine in the Sandbox

Modify the sandbox server (`sandbox_server.py`) to handle `handlerType: WORKFLOW` requests. This involves fetching the workflow YAML, parsing it, and iterating through the steps, invoking the appropriate JIT, LLM, or MCP logic for each step based on the definition.

**Context:**
*   Server File: `@sandbox_images/python_runner/sandbox_server.py`
*   MCP Client: `MCPClient` class within the server file.
*   Workflow Schema: `@schemas/workflow_definition.schema.json` (for understanding structure)
*   Design Docs: `05-workflow-yaml.md` [8, 21], Section 6 [15, 21], `02-sandbox-api.md` [5].
*   Dependencies: Add `PyYAML` to requirements if not already present. Need robust expression evaluation library (consider simple dot notation access for V1, e.g., using `jsonpath-ng` or custom basic parser).

**Plan:**

1.  **Update Dependencies:** Use `read_file` on `@sandbox_images/python_runner/requirements.txt`. Add `PyYAML` and potentially `jsonpath-ng` (for expression evaluation). Use `write_to_file` to save the updated requirements. Use `execute_command` (if simulating build) or manually ensure these are installed (`pip install PyYAML jsonpath-ng`).
2.  **Read Server File:** Use `read_file` to get the content of `@sandbox_images/python_runner/sandbox_server.py`.
3.  **Locate Workflow Handler Block:** Find the (likely placeholder) `elif request.context.handlerType == "WORKFLOW":` block within the `execute` function.
4.  **Implement Workflow Logic:** Replace the placeholder logic within the WORKFLOW block with a more comprehensive structure:
    *   **Extract Workflow ID:** Get `workflow_id = request.context.taskDetails.get("workflowId")`. Validate it exists.
    *   **Fetch Workflow YAML:** Use `mcp_client.call_tool` to call `core.state.getDefinitionFileContent` with `params={"app_id": request.context.appId, "file_path": f"workflows/{workflow_id}.yaml"}` (assuming standard path, adjust if path is in taskDetails). Handle MCP errors.
    *   **Parse Workflow YAML:** Decode the content and use `yaml.safe_load()` to parse the workflow definition. Handle YAML parsing errors. Validate the parsed structure against `schemas/workflow_definition.schema.json` (optional but recommended using `jsonschema`).
    *   **Initialize State:**
        *   Create `workflow_context` dictionary to hold data across steps. Initialize it with initial `requestData` and `context`. E.g., `workflow_context = {"input": request.requestData, "context": request.context.dict(), "steps": {}}`.
        *   Set `current_step_id = workflow_def['startAt']`.
        *   Set `max_steps = 20` (or configurable) to prevent infinite loops. `step_count = 0`.
    *   **Execution Loop:** Start a `while current_step_id and step_count < max_steps:` loop.
        *   `step_count += 1`.
        *   Log entry into the current step (`current_step_id`).
        *   Get the current step definition: `step_def = workflow_def['steps'].get(current_step_id)`. Handle step not found error.
        *   **Process Input Mapping (V1 - Basic):** Evaluate `step_def.get('inputMapping', {})`. For each mapping `{"targetVar": "$.source.path"}`, use a basic parser (like `jsonpath-ng` or custom dot notation function) to extract data from `workflow_context` and create `step_input_data` dictionary for the current step. Handle expression errors.
        *   **Execute Step based on `type`:** Use an `if/elif/else` block for `step_def['type']`:
            *   **`jit`:** Call the existing JIT handler logic (refactored into a helper function `async def _execute_jit_step(...)`) passing the `step_input_data` and relevant context.
            *   **`llm`:** Call the existing LLM handler logic (refactored into `async def _execute_llm_step(...)`) passing `step_input_data` and context.
            *   **`mcp`:** Extract `tool_name = step_def['target']` and `params` (potentially merging `step_input_data` with `step_def.get('params')`). Call `mcp_client.call_tool(tool_name, params, context)`.
            *   **`control`:** Handle subtypes. For `formatResponse` [8]: Prepare the final `data` based on mapping from `workflow_context`. Set `resultType`. Force transition to `end`.
            *   **Error Handling:** Wrap step execution in `try...except`. Store any error result in `step_output`.
        *   **Store Step Output:** Store the result (success data or error object) in `workflow_context['steps'][current_step_id] = step_output`.
        *   **Determine Next Step (Transitions):**
            *   Check if `step_def.get('end') == True`. If so, break the loop.
            *   Check if an error occurred. If yes, look for `step_def['transitions'].get('onFailureDefault')`. If present, set `current_step_id` to it. Otherwise, break loop and record workflow failure.
            *   If success, check `step_def['transitions'].get('conditionalTransitions')`. Evaluate conditions (basic string comparison for V1) against `step_output` or `workflow_context`. If a condition matches, set `current_step_id` to its `nextStepId` and continue loop.
            *   If no conditions match (or none defined), look for `step_def['transitions'].get('onSuccess')`. Set `current_step_id` to it.
            *   If no transition rule applies, break loop and record workflow failure/end.
    *   **Prepare Final Response:** After the loop:
        *   If loop ended due to `end: true` or explicit `formatResponse`, use the final formatted data/resultType. Check if `step_output` has the final response structure.
        *   If loop ended due to error or max steps reached, format an appropriate error `ExecuteResponse`.
        *   If loop ended unexpectedly, format an error response.
    *   **Return Result:** Return the final `ExecuteResponse`.
5.  **Refactor Handlers:** Refactor the JIT and LLM logic implemented in Phase 3 into separate `async def _execute_jit_step(...)` and `async def _execute_llm_step(...)` helper functions within the file so they can be called by both the direct `/execute` handler and the workflow engine. These helpers should accept necessary parameters (like script path, template path, input data, context, mcp_client) and return the result data or raise an exception.
6.  **Add Imports:** Ensure `yaml`, `jsonpath_ng` (if used) are imported.
7.  **Save Changes:** Use `write_to_file` to save the modified content back to `@sandbox_images/python_runner/sandbox_server.py`.

**Expected Outcome:**
*   The WORKFLOW handler block in `@sandbox_images/python_runner/sandbox_server.py` is implemented with the core workflow execution loop logic.
*   JIT and LLM logic is refactored into helper functions.
*   `sandbox_images/python_runner/requirements.txt` is updated with necessary dependencies (`PyYAML`, `jsonpath-ng`).