### 1.4 Key Differentiators

## 2. User Interface & Interaction (MVP Essentials)

*   Primary Interface – The Nexus Chat Window:
    The cornerstone of user interaction will be a persistent, context-aware chat window. This is where users engage in natural language conversations with their personalized AI assistant, Nexus. Through this interface, users will:
    *   Define and refine project goals and requirements (e.g., "Nexus, let's start a new project to analyze customer feedback from our support tickets. The main goal is to identify common pain points.").
    *   Request Nexus to perform actions (e.g., "Nexus, create a new app based on the 'Sentiment Analysis' template," "Generate Python code to fetch data from this API endpoint {url}," "Summarize the key findings in the 'research_notes.md' file," "Run Project Alpha and show me its output.").
    *   Receive guidance, suggestions, and feedback from Nexus (e.g., "Okay, I've created the 'Sentiment Analysis' app. To get started, you'll need to provide an API key for the sentiment analysis service. Would you like me to guide you through that?").
    *   Troubleshoot issues and manage project settings (e.g., "Nexus, Project Alpha seems to be running slow, can you check its logs?" or "Change the default LLM for this project to Claude 3 Sonnet.").
    The chat interface must support rich interaction. For the MVP/POC, text-based input is primary. However, the architecture should consider future support for multimodal input (e.g., users pasting images for analysis, uploading documents for context, or even voice commands if feasible in later stages). The context awareness means Nexus should remember the current project, recent interactions, and user preferences to make conversations feel natural and efficient.
*   The Canvas – A Dynamic Content Workspace:
    A versatile "canvas" area will serve as the primary view for displaying and interacting with content generated by apps or Nexus. It's a dynamic workspace that adapts to the type of content being handled. For the MVP/POC, this includes:
    *   **Viewing**:
        *   Text documents (plain text, Markdown with preview).
        *   Source code (with basic syntax highlighting for common languages like Python, JavaScript, YAML, JSON). Features like code folding for JSON/YAML would enhance readability.
        *   Simple image formats (e.g., PNG, JPEG).
    *   **Basic Edits**:
        *   **Text/Code**: Users should be able to make direct text edits within the canvas. For code, while a full IDE experience is out of scope for POC, basic syntax highlighting is essential. Nexus could potentially provide simple auto-completion hints or linting feedback conversationally if the user asks for a review of the code on the canvas.
        *   Images (POC): Simple manipulations such as cropping to a selected area, perhaps basic color adjustments (e.g., brightness/contrast sliders if simple to implement), or markup/annotations (e.g., drawing simple arrows or text overlays to highlight parts of an image when providing feedback to Nexus). The ability to "Save As" a modified version of an image, or save the annotated image, would be valuable.
    The core principle of the canvas is to provide a visually rich, formatted representation of data, moving beyond plain text outputs, and allowing users to take manual control when needed. It's where the "work" of the app often becomes tangible. A key interaction pattern is for users to open a file (e.g., a Python script, a Markdown document) in the canvas and then, through a clearly identifiable button or a conversational command like "Nexus, look at this file," initiate a discussion with Nexus specifically about that content. Nexus should then be aware of the file being viewed, allowing the user to ask questions ("What does this function do?") or request modifications ("Change the title in this document to 'Q2 Report'"). The context of the active canvas item should be implicitly passed to Nexus.
*   Minimal Screens & Overlays – Focus on Flow:
    The platform UI should be lean and avoid a proliferation of complex, multi-layered screens or traditional dashboards, especially for the MVP. Most interactions should flow naturally through the primary chat interface and the adaptive canvas. Contextual overlays might appear for specific, focused tasks (e.g., a file version history dropdown when viewing a file, a simple tool configuration pop-up if an MCP tool requires parameters not suitable for chat input, or a confirmation dialog for critical actions). These overlays should be non-intrusive and quickly dismissible, ensuring they don't disrupt the primary conversational and content-focused user experience. The underlying philosophy is that users derive enjoyment and value from what they make and achieve with the platform; the UI's role is to facilitate this creative and productive process with minimal friction and cognitive load.
*   App Management Toolbar (POC Functionality):
    When an app or project is selected or active (e.g., its content is being viewed on the canvas, or it's the subject of the current chat conversation with Nexus), a simple, contextual toolbar should provide essential, predefined buttons for core lifecycle actions. For the POC, this should include:
    *   **"Start"**: To initiate the execution of the app's defined start script (as specified in its AppDefinition) within its dedicated Docker container.
    *   **"Stop"**: To terminate the running app container.
    *   "Restart": To gracefully stop and then start the app container, effectively reloading it.
    These actions, when triggered, must provide clear visual feedback in the UI. For example, status indicators next to the app's name could change (e.g., from "Stopped" to "Starting..." to "Running"), button icons might change, or brief toast notifications could confirm the action's initiation and completion.
*   Running App Interaction – Modality-Driven Presentation:
    The way a user interacts with a "running" app will depend on the nature of the app itself, as defined by its creator. The platform must flexibly accommodate various interaction modalities:
    *   **Conversational/Agentic Apps**: For applications that are primarily dialogue-based (e.g., a custom Q&A chatbot, a research assistant agent, an interactive personality test), these will typically run using the **same agentic chat interface** the user is already familiar with for interacting with Nexus. However, when the specific app is "running," Nexus (or the agent instance embodying the app) operates strictly based on the prompts, logic, tools, and functions defined specifically for *that application*. It's as if Nexus adopts the "persona," knowledge base, and operational parameters of the running app. There should be a clear visual cue to the user indicating that they are now interacting with the "running app" persona versus the general "Nexus assistant" persona.
    *   **Web-based Apps (POC Simplification)**: If the app created by the user is a website or a web application (e.g., a simple static site generated by Nexus, or a dynamic web app with its own backend logic), the POC should provide a straightforward way to display and interact with it. This could be an embedded view (e.g., using an iframe within a dedicated panel on the canvas) or by opening the app in a new browser tab. The AppDefinition might include a field specifying the app's output type or preferred display method. The app itself might have its own internal UI and interaction elements (including its own chat interface, if it was designed that way by its creator). Security considerations for iframes (like sandboxing attributes) should be kept in mind even for the POC if this route is taken.
    *   **CLI-based Apps (POC Simplification)**: If the user's app is designed as a command-line tool or script, the platform should provide a basic "dummy shell" or a text-based terminal-like interface. This interface would allow users to type commands or provide input to the CLI app and see its textual output, all happening within the app's running Docker container. This could be a panel on the canvas. Basic features like command history within this dummy shell would be a plus.
*   Switching Context Between App and Nexus:
    Users must have a clear and intuitive mechanism to switch their interaction focus between a live, running application and engaging with the overarching Nexus assistant for broader platform commands, project management tasks (e.g., stopping the current app, viewing its logs, modifying its AppDefinition), or working on entirely different projects.
    *   **Embedded Apps**: If an application runs within an embedded view (such as an iframe or a dedicated panel on the canvas), the primary Nexus chat window and the project management toolbar should ideally remain visible and accessible within the main platform UI. This allows the user to seamlessly shift their focus – for example, they could be interacting with their web app in one panel and simultaneously ask Nexus a question about its performance in the chat window. Clear visual delineation between the app's embedded UI and the platform's UI is important.
    *   **Separate Tab/Window Apps**: If an application, by its nature (e.g., a standard website), opens in a new browser tab or window, the user would use standard browser navigation (switching tabs) to return to the original Nexus CoCreate AI platform tab. This original platform tab then effectively serves as the "control panel" or "admin view" for that project, where they can interact with Nexus or use the project toolbar for management tasks. The platform could provide a clear "Return to Project Management" button or link if an app is launched externally.
